{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Importaciones requeridas del programa\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import RandomForestClassifier as RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizarFrase(frase):    \n",
    "    archivoTemporalConFrase = open('temporalFile.txt','w')    \n",
    "    archivoTemporalConFrase.write(frase)\n",
    "    archivoTemporalConFrase.close()\n",
    "\n",
    "    file = {'file': open('temporalFile.txt', 'r')}\n",
    "    params = {'outf': 'tagged', 'format': 'json'}\n",
    "\n",
    "    url = \"http://www.corpus.unam.mx/servicio-freeling/analyze.php\"\n",
    "    r = requests.post(url, files=file, params=params)\n",
    "    obj = r.json()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerDictionaryDeSenticol():\n",
    "    archivoDeBaseDeDatos = open('MLSenticon.txt','r',  encoding='cp1252')\n",
    "    palabras = archivoDeBaseDeDatos.read().split('\\n')\n",
    "    diccionarioDePalabrasConSentimientos = {}    \n",
    "    for palabra in palabras:\n",
    "        tmpPalabraConSentimiento = palabra.split('\\t')\n",
    "        diccionarioDePalabrasConSentimientos[tmpPalabraConSentimiento[0]] = tmpPalabraConSentimiento[1]\n",
    "    return diccionarioDePalabrasConSentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leerBaseDeDatosDeReviews():\n",
    "    archivoDeBaseDeDatos = open('database.txt','r')\n",
    "    reviewsData = archivoDeBaseDeDatos.read().split('\\n')\n",
    "    archivoDeBaseDeDatos.close()\n",
    "    reviews, tipoDeReview = [],[] \n",
    "    for reviewData in reviewsData:\n",
    "        temporalData = reviewData.split('\\t')\n",
    "        reviews.append(temporalData[0])\n",
    "        tipoDeReview.append(temporalData[1])\n",
    "    return reviews, tipoDeReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representacionVectorial(reviewTokenizado, diccionarioDeSentimientos):    \n",
    "    representacion = [0, 0]\n",
    "    palabrasDeNegacion = ['pero', 'no']\n",
    "    finalizacionDeFrase = ['.', ',']\n",
    "    signoParaMultiplicarLasPalabras = 1\n",
    "    representacionTemporal = [0, 0]\n",
    "    \n",
    "    \n",
    "    for sentence in reviewTokenizado: \n",
    "        for word in sentence:\n",
    "            lemma = word['lemma']\n",
    "            if (lemma in finalizacionDeFrase):\n",
    "                representacion[0] += representacionTemporal[0] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[1]\n",
    "                representacion[1] += representacionTemporal[1] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[0]\n",
    "                representacionTemporal = [0, 0]\n",
    "            elif (lemma in palabrasDeNegacion):\n",
    "                signoParaMultiplicarLasPalabras = signoParaMultiplicarLasPalabras * (- 1);\n",
    "            elif (word['tag'][0] == 'A' and lemma in diccionarioDeSentimientos.keys()):\n",
    "                representacionTemporal[0] = representacionTemporal[0] + (float(diccionarioDeSentimientos[lemma]) if (float(diccionarioDeSentimientos[lemma]) > 0) else 0)\n",
    "                representacionTemporal[1] = representacionTemporal[1] + (float(diccionarioDeSentimientos[lemma]) if (float(diccionarioDeSentimientos[lemma]) < 0) else 0)\n",
    "            representacion[0] += representacionTemporal[0] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[1]\n",
    "            representacion[1] += representacionTemporal[1] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[0]\n",
    "            representacionTemporal = [0, 0]\n",
    "    representacion[1] *= -1 if (representacion[1] < 0) else 1\n",
    "    representacion[0] *= -1 if (representacion[0] < 0) else 1\n",
    "\n",
    "    return representacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_measures(Yestimado, Yteorico):\n",
    "    \n",
    "    CM = confusion_matrix(Yteorico, Yestimado)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    sens = TP/(TP+FN)\n",
    "    esp = TN/(TN+FP)\n",
    "    \n",
    "    return sens, esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecinosMasCercanos(data, target):\n",
    "    model = KNN()\n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(data, target)\n",
    "        model.fit(Xtrain,Ytrain)\n",
    "        \n",
    "        Yest = model.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(model.score(Xtest,Ytest))\n",
    "    print(\"\\nResultados con Regresión logística (Lineal)\\n\")\n",
    "    print(\"Accuracy: \", np.mean(acc), \"+/-\", np.std(acc))\n",
    "    print(\"Sensitivity: \", np.mean(sens), \"+/-\", np.std(sens))\n",
    "    print(\"Especificity: \", np.mean(esp), \"+/-\", np.std(esp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresionLogistica(data, target):\n",
    "    lr = LogisticRegression()\n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "\n",
    "    for i in range(100):\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(data, target)\n",
    "        lr.fit(Xtrain,Ytrain)        \n",
    "        Yest = lr.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(lr.score(Xtest,Ytest))\n",
    "        \n",
    "    print(\"\\nResultados con Regresión logística (Lineal)\\n\")\n",
    "    print(\"Accuracy: \", np.mean(acc), \"+/-\", np.std(acc))\n",
    "    print(\"Sensitivity: \", np.mean(sens), \"+/-\", np.std(sens))\n",
    "    print(\"Especificity: \", np.mean(esp), \"+/-\", np.std(esp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificadorRandomForest(data, target):\n",
    "    model = RF()\n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(data, target)\n",
    "        model.fit(Xtrain,Ytrain)\n",
    "        \n",
    "        Yest = model.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(model.score(Xtest,Ytest))\n",
    "    print(\"\\nResultados con Regresión logística (Lineal)\\n\")\n",
    "    print(\"Accuracy: \", np.mean(acc), \"+/-\", np.std(acc))\n",
    "    print(\"Sensitivity: \", np.mean(sens), \"+/-\", np.std(sens))\n",
    "    print(\"Especificity: \", np.mean(esp), \"+/-\", np.std(esp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con Regresión logística (Lineal)\n",
      "\n",
      "Accuracy:  0.7525 +/- 0.0744460837637219\n",
      "Sensitivity:  0.6411563177964106 +/- 0.11463012254642858\n",
      "Especificity:  0.8887050678080091 +/- 0.08530670718040971\n",
      "\n",
      "Resultados con Regresión logística (Lineal)\n",
      "\n",
      "Accuracy:  0.6996428571428571 +/- 0.10511109283389025\n",
      "Sensitivity:  0.725768832732455 +/- 0.1765907776119261\n",
      "Especificity:  0.6855135836385837 +/- 0.3171868663973595\n",
      "\n",
      "Resultados con Regresión logística (Lineal)\n",
      "\n",
      "Accuracy:  0.6960714285714285 +/- 0.07684715150138977\n",
      "Sensitivity:  0.5364834714219389 +/- 0.12449217508663374\n",
      "Especificity:  0.8799413927575693 +/- 0.08205391029730864\n"
     ]
    }
   ],
   "source": [
    "diccionarioDeSentimientos = obtenerDictionaryDeSenticol()\n",
    "data, target = leerBaseDeDatosDeReviews()\n",
    "dataRepresentadaEnVectores = []\n",
    "\n",
    "for review in data:\n",
    "    dataRepresentadaEnVectores.append(representacionVectorial(tokenizarFrase(review), diccionarioDeSentimientos))\n",
    "\n",
    "regresionLogistica(dataRepresentadaEnVectores, target)\n",
    "vecinosMasCercanos(dataRepresentadaEnVectores, target)\n",
    "clasificadorRandomForest(dataRepresentadaEnVectores, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
