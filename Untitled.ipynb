{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre: Luis Eduardo Palacios Arboleda\n",
    "#### Cédula: 1077455789\n",
    "\n",
    "### Nombre: Susana Sepúlveda\n",
    "#### Cédula: 1077455789\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Importaciones requeridas del programa\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizarFrase(frase):    \n",
    "    archivoTemporalConFrase = open('temporalFile.txt','w')    \n",
    "    archivoTemporalConFrase.write(frase)\n",
    "    archivoTemporalConFrase.close()\n",
    "\n",
    "    file = {'file': open('temporalFile.txt', 'r')}\n",
    "    params = {'outf': 'tagged', 'format': 'json'}\n",
    "\n",
    "    url = \"http://www.corpus.unam.mx/servicio-freeling/analyze.php\"\n",
    "    r = requests.post(url, files=file, params=params)\n",
    "    obj = r.json()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerDictionaryDeSenticol():\n",
    "    archivoDeBaseDeDatos = open('MLSenticon.txt','r',  encoding='cp1252')\n",
    "    palabras = archivoDeBaseDeDatos.read().split('\\n')\n",
    "    diccionarioDePalabrasConSentimientos = {}    \n",
    "    for palabra in palabras:\n",
    "        tmpPalabraConSentimiento = palabra.split('\\t')\n",
    "        diccionarioDePalabrasConSentimientos[tmpPalabraConSentimiento[0]] = tmpPalabraConSentimiento[1]\n",
    "    return diccionarioDePalabrasConSentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leerBaseDeDatosDeReviews():\n",
    "    archivoDeBaseDeDatos = open('database.txt','r')\n",
    "    reviewsData = archivoDeBaseDeDatos.read().split('\\n')\n",
    "    archivoDeBaseDeDatos.close()\n",
    "    reviews, tipoDeReview = [],[] \n",
    "    for reviewData in reviewsData:\n",
    "        temporalData = reviewData.split('\\t')\n",
    "        reviews.append(temporalData[0])\n",
    "        tipoDeReview.append(temporalData[1])\n",
    "    return reviews, tipoDeReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representacionVectorial(reviewTokenizado, diccionarioDeSentimientos):    \n",
    "    representacion = [0, 0]\n",
    "    palabrasDeNegacion = ['pero', 'no']\n",
    "    finalizacionDeFrase = ['.', ',']\n",
    "    signoParaMultiplicarLasPalabras = 1\n",
    "    representacionTemporal = [0, 0]\n",
    "    \n",
    "    \n",
    "    for sentence in reviewTokenizado: \n",
    "        for word in sentence:\n",
    "            lemma = word['lemma']\n",
    "            if (lemma in finalizacionDeFrase):\n",
    "                representacion[0] += representacionTemporal[0] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[1]\n",
    "                representacion[1] += representacionTemporal[1] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[0]\n",
    "                representacionTemporal = [0, 0]\n",
    "            elif (lemma in palabrasDeNegacion):\n",
    "                signoParaMultiplicarLasPalabras = signoParaMultiplicarLasPalabras * (- 1);\n",
    "            elif (word['tag'][0] == 'A' and lemma in diccionarioDeSentimientos.keys()):\n",
    "                representacionTemporal[0] = representacionTemporal[0] + (float(diccionarioDeSentimientos[lemma]) if (float(diccionarioDeSentimientos[lemma]) > 0) else 0)\n",
    "                representacionTemporal[1] = representacionTemporal[1] + (float(diccionarioDeSentimientos[lemma]) if (float(diccionarioDeSentimientos[lemma]) < 0) else 0)\n",
    "            representacion[0] += representacionTemporal[0] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[1]\n",
    "            representacion[1] += representacionTemporal[1] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[0]\n",
    "            representacionTemporal = [0, 0]\n",
    "    representacion[1] *= -1 if (representacion[1] < 0) else 1\n",
    "    representacion[0] *= -1 if (representacion[0] < 0) else 1\n",
    "\n",
    "    return representacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_measures(Yestimado, Yteorico):\n",
    "    \n",
    "    CM = confusion_matrix(Yteorico, Yestimado)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    sens = TP/(TP+FN)\n",
    "    esp = TN/(TN+FP)\n",
    "    \n",
    "    return sens, esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepararDatosParaPintar(datoAPreparar):\n",
    "    return str(np.mean(datoAPreparar))[:5] + ' +/- '+ str(np.std(datoAPreparar))[:5]    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pintarDatos(Modelo, Eficiencia, especcificidad, sensibilidad, datoExtra):\n",
    "    print(\"Datos de\", Modelo)\n",
    "    datos = {'Eficiencia' : Eficiencia,\n",
    "                   'Espicificidad' : especcificidad,\n",
    "                    'Sensibilidad': sensibilidad}\n",
    "    if (datoExtra != 0):\n",
    "        datoExtra.update(datos)\n",
    "        datos = datoExtra\n",
    "    df = pd.DataFrame(datos)\n",
    "    print (tabulate(df, headers='keys', tablefmt='psql'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecinosMasCercanos(data, target, k_neighbors):\n",
    "    accAcum = []\n",
    "    sensAcum = []\n",
    "    espAcum = []\n",
    "\n",
    "    \n",
    "    for n_neighbor in k_neighbors:\n",
    "        model = KNN(n_neighbors = n_neighbor)\n",
    "        acc = []\n",
    "        sens = []\n",
    "        esp = []\n",
    "\n",
    "        for i in range(100):\n",
    "\n",
    "            Xtrain, Xtest, Ytrain, Ytest = train_test_split(data, target)\n",
    "            model.fit(Xtrain,Ytrain)\n",
    "\n",
    "            Yest = model.predict(Xtest)\n",
    "            s, e = error_measures(Yest,Ytest)\n",
    "            sens.append(s); esp.append(e)\n",
    "            acc.append(model.score(Xtest,Ytest))\n",
    "\n",
    "        accAcum.append(prepararDatosParaPintar(acc))\n",
    "        sensAcum.append(prepararDatosParaPintar(sens))\n",
    "        espAcum.append(prepararDatosParaPintar(esp))    \n",
    "        \n",
    "    pintarDatos('Vecinos Más Cercanos', accAcum, espAcum, sensAcum , {'k_neighbors' : k_neighbors})     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresionLogistica(data, target):\n",
    "    lr = LogisticRegression()\n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "    \n",
    "\n",
    "    for i in range(100):\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(data, target)\n",
    "        lr.fit(Xtrain,Ytrain)        \n",
    "        Yest = lr.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(lr.score(Xtest,Ytest))\n",
    "        \n",
    "    pintarDatos('Regresión Logística', [prepararDatosParaPintar(acc)], [prepararDatosParaPintar(esp)], [prepararDatosParaPintar(sens)] , 0)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificadorRandomForest(data, target, n_estimators):\n",
    "    \n",
    "    accAcum = []\n",
    "    sensAcum = []\n",
    "    espAcum = []\n",
    "\n",
    "    \n",
    "    for n_estimator in n_estimators:\n",
    "        model = RF(n_estimators = n_estimator)\n",
    "        acc = []\n",
    "        sens = []\n",
    "        esp = []\n",
    "\n",
    "        for i in range(100):\n",
    "\n",
    "            Xtrain, Xtest, Ytrain, Ytest = train_test_split(data, target)\n",
    "            model.fit(Xtrain,Ytrain)\n",
    "\n",
    "            Yest = model.predict(Xtest)\n",
    "            s, e = error_measures(Yest,Ytest)\n",
    "            sens.append(s); esp.append(e)\n",
    "            acc.append(model.score(Xtest,Ytest))\n",
    "\n",
    "        accAcum.append(prepararDatosParaPintar(acc))\n",
    "        sensAcum.append(prepararDatosParaPintar(sens))\n",
    "        espAcum.append(prepararDatosParaPintar(esp))    \n",
    "        \n",
    "    pintarDatos('Bosque Aleatorio', accAcum, espAcum, sensAcum , {'n_estimators' : n_estimators})     \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devolverDataEnVectores(data):\n",
    "    dataRepresentadaEnVectores = []\n",
    "    for review in data:\n",
    "        dataRepresentadaEnVectores.append(representacionVectorial(tokenizarFrase(review), diccionarioDeSentimientos))\n",
    "    return dataRepresentadaEnVectores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realizarModelos(datosAModelar, targetsParaModelar):\n",
    "    regresionLogistica(datosAModelar, targetsParaModelar)\n",
    "    vecinosMasCercanos(datosAModelar, targetsParaModelar, [1,3,5,7,9,15,25])\n",
    "    clasificadorRandomForest(datosAModelar, targetsParaModelar, [10,20,30,40,50])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtencion de datos\n",
    "data, target = leerBaseDeDatosDeReviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <----- Representacion de vectores con cargas --------->\n",
      "Datos de Regresión Logística\n",
      "+----+-----------------+-----------------+-----------------+\n",
      "|    | Eficiencia      | Espicificidad   | Sensibilidad    |\n",
      "|----+-----------------+-----------------+-----------------|\n",
      "|  0 | 0.722 +/- 0.082 | 0.871 +/- 0.082 | 0.602 +/- 0.105 |\n",
      "+----+-----------------+-----------------+-----------------+\n",
      "Datos de Vecinos Más Cercanos\n",
      "+----+---------------+-----------------+-----------------+-----------------+\n",
      "|    |   k_neighbors | Eficiencia      | Espicificidad   | Sensibilidad    |\n",
      "|----+---------------+-----------------+-----------------+-----------------|\n",
      "|  0 |             1 | 0.622 +/- 0.096 | 0.617 +/- 0.351 | 0.626 +/- 0.204 |\n",
      "|  1 |             3 | 0.68 +/- 0.110  | 0.645 +/- 0.357 | 0.705 +/- 0.194 |\n",
      "|  2 |             5 | 0.718 +/- 0.099 | 0.741 +/- 0.294 | 0.699 +/- 0.172 |\n",
      "|  3 |             7 | 0.707 +/- 0.105 | 0.688 +/- 0.341 | 0.742 +/- 0.179 |\n",
      "|  4 |             9 | 0.722 +/- 0.099 | 0.786 +/- 0.278 | 0.679 +/- 0.151 |\n",
      "|  5 |            15 | 0.719 +/- 0.090 | 0.823 +/- 0.206 | 0.634 +/- 0.146 |\n",
      "|  6 |            25 | 0.731 +/- 0.087 | 0.845 +/- 0.177 | 0.642 +/- 0.134 |\n",
      "+----+---------------+-----------------+-----------------+-----------------+\n",
      "Datos de Bosque Aleatorio\n",
      "+----+----------------+-----------------+-----------------+-----------------+\n",
      "|    |   n_estimators | Eficiencia      | Espicificidad   | Sensibilidad    |\n",
      "|----+----------------+-----------------+-----------------+-----------------|\n",
      "|  0 |             10 | 0.688 +/- 0.076 | 0.856 +/- 0.078 | 0.539 +/- 0.124 |\n",
      "|  1 |             20 | 0.695 +/- 0.078 | 0.878 +/- 0.080 | 0.541 +/- 0.124 |\n",
      "|  2 |             30 | 0.680 +/- 0.073 | 0.867 +/- 0.090 | 0.523 +/- 0.125 |\n",
      "|  3 |             40 | 0.696 +/- 0.065 | 0.861 +/- 0.088 | 0.554 +/- 0.108 |\n",
      "|  4 |             50 | 0.681 +/- 0.074 | 0.873 +/- 0.078 | 0.523 +/- 0.117 |\n",
      "+----+----------------+-----------------+-----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# Representacion de vectores con cargas\n",
    "\n",
    "print(\" <----- Representacion de vectores con cargas --------->\")\n",
    "diccionarioDeSentimientos = obtenerDictionaryDeSenticol()\n",
    "dataRepresentadaEnVectores = devolverDataEnVectores(data)\n",
    "#print(dataRepresentadaEnVectores)\n",
    "realizarModelos(dataRepresentadaEnVectores, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <----- Representacion TfidVectorizer --------->\n",
      "Datos de Regresión Logística\n",
      "+----+-----------------+-----------------+-----------------+\n",
      "|    | Eficiencia      | Espicificidad   | Sensibilidad    |\n",
      "|----+-----------------+-----------------+-----------------|\n",
      "|  0 | 0.802 +/- 0.086 | 0.729 +/- 0.184 | 0.896 +/- 0.097 |\n",
      "+----+-----------------+-----------------+-----------------+\n",
      "Datos de Vecinos Más Cercanos\n",
      "+----+---------------+-----------------+-----------------+-----------------+\n",
      "|    |   k_neighbors | Eficiencia      | Espicificidad   | Sensibilidad    |\n",
      "|----+---------------+-----------------+-----------------+-----------------|\n",
      "|  0 |             1 | 0.833 +/- 0.054 | 0.737 +/- 0.107 | 0.918 +/- 0.066 |\n",
      "|  1 |             3 | 0.791 +/- 0.067 | 0.660 +/- 0.116 | 0.910 +/- 0.062 |\n",
      "|  2 |             5 | 0.784 +/- 0.079 | 0.624 +/- 0.134 | 0.931 +/- 0.057 |\n",
      "|  3 |             7 | 0.752 +/- 0.080 | 0.585 +/- 0.139 | 0.912 +/- 0.070 |\n",
      "|  4 |             9 | 0.742 +/- 0.085 | 0.563 +/- 0.158 | 0.907 +/- 0.067 |\n",
      "|  5 |            15 | 0.737 +/- 0.088 | 0.516 +/- 0.156 | 0.934 +/- 0.066 |\n",
      "|  6 |            25 | 0.713 +/- 0.075 | 0.461 +/- 0.129 | 0.944 +/- 0.061 |\n",
      "+----+---------------+-----------------+-----------------+-----------------+\n",
      "Datos de Bosque Aleatorio\n",
      "+----+----------------+-----------------+-----------------+-----------------+\n",
      "|    |   n_estimators | Eficiencia      | Espicificidad   | Sensibilidad    |\n",
      "|----+----------------+-----------------+-----------------+-----------------|\n",
      "|  0 |             10 | 0.743 +/- 0.079 | 0.755 +/- 0.147 | 0.764 +/- 0.143 |\n",
      "|  1 |             20 | 0.777 +/- 0.071 | 0.764 +/- 0.156 | 0.803 +/- 0.121 |\n",
      "|  2 |             30 | 0.767 +/- 0.079 | 0.715 +/- 0.158 | 0.835 +/- 0.117 |\n",
      "|  3 |             40 | 0.802 +/- 0.070 | 0.774 +/- 0.150 | 0.844 +/- 0.109 |\n",
      "|  4 |             50 | 0.777 +/- 0.076 | 0.721 +/- 0.148 | 0.850 +/- 0.109 |\n",
      "+----+----------------+-----------------+-----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# Con TfidVectorizer\n",
    "print(\" <----- Representacion TfidVectorizer --------->\")\n",
    "\n",
    "vector = TfidfVectorizer()\n",
    "vector.fit(data)\n",
    "bow = vector.transform(data)\n",
    "realizarModelos(bow,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <----- Representacion CountVectorizer --------->\n",
      "Datos de Regresión Logística\n",
      "+----+-----------------+-----------------+-----------------+\n",
      "|    | Eficiencia      | Espicificidad   | Sensibilidad    |\n",
      "|----+-----------------+-----------------+-----------------|\n",
      "|  0 | 0.812 +/- 0.076 | 0.744 +/- 0.145 | 0.880 +/- 0.088 |\n",
      "+----+-----------------+-----------------+-----------------+\n",
      "Datos de Vecinos Más Cercanos\n",
      "+----+---------------+-----------------+-----------------+-----------------+\n",
      "|    |   k_neighbors | Eficiencia      | Espicificidad   | Sensibilidad    |\n",
      "|----+---------------+-----------------+-----------------+-----------------|\n",
      "|  0 |             1 | 0.620 +/- 0.082 | 0.416 +/- 0.208 | 0.792 +/- 0.117 |\n",
      "|  1 |             3 | 0.639 +/- 0.099 | 0.520 +/- 0.241 | 0.757 +/- 0.196 |\n",
      "|  2 |             5 | 0.676 +/- 0.086 | 0.612 +/- 0.207 | 0.743 +/- 0.181 |\n",
      "|  3 |             7 | 0.659 +/- 0.101 | 0.568 +/- 0.249 | 0.770 +/- 0.185 |\n",
      "|  4 |             9 | 0.646 +/- 0.087 | 0.461 +/- 0.234 | 0.822 +/- 0.161 |\n",
      "|  5 |            15 | 0.622 +/- 0.093 | 0.449 +/- 0.277 | 0.812 +/- 0.201 |\n",
      "|  6 |            25 | 0.610 +/- 0.111 | 0.480 +/- 0.306 | 0.771 +/- 0.243 |\n",
      "+----+---------------+-----------------+-----------------+-----------------+\n",
      "Datos de Bosque Aleatorio\n",
      "+----+----------------+-----------------+-----------------+-----------------+\n",
      "|    |   n_estimators | Eficiencia      | Espicificidad   | Sensibilidad    |\n",
      "|----+----------------+-----------------+-----------------+-----------------|\n",
      "|  0 |             10 | 0.732 +/- 0.083 | 0.715 +/- 0.185 | 0.771 +/- 0.176 |\n",
      "|  1 |             20 | 0.74 +/- 0.095  | 0.673 +/- 0.187 | 0.831 +/- 0.169 |\n",
      "|  2 |             30 | 0.761 +/- 0.086 | 0.663 +/- 0.181 | 0.876 +/- 0.146 |\n",
      "|  3 |             40 | 0.782 +/- 0.085 | 0.668 +/- 0.186 | 0.907 +/- 0.106 |\n",
      "|  4 |             50 | 0.767 +/- 0.091 | 0.661 +/- 0.201 | 0.893 +/- 0.130 |\n",
      "+----+----------------+-----------------+-----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# Con CountVectorizer\n",
    "\n",
    "print(\" <----- Representacion CountVectorizer --------->\")\n",
    "\n",
    "\n",
    "vector = CountVectorizer(ngram_range=(1,2))\n",
    "vector.fit(data)\n",
    "bow = vector.transform(data)\n",
    "realizarModelos(bow,target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
