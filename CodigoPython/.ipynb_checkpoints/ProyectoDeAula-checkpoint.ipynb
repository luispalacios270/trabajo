{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre: Luis Eduardo Palacios Arboleda\n",
    "#### Cédula: 1077455789\n",
    "\n",
    "### Nombre: Susana Sepúlveda\n",
    "#### Cédula: 1017238114\n",
    "\n",
    "\n",
    "Link al hotel seleccionado:\n",
    "\n",
    "City Express Junior Bogota Aeropuerto\n",
    "https://www.booking.com/hotel/co/city-express-junior-bogota-aeropuerto.es.html?aid=397642;label=gog235jc-index-es-XX-XX-unspec-co-com-L%3Aes-O%3AwindowsS10-B%3Achrome-N%3AXX-S%3Abo-U%3Ac-H%3As;sid=a7a62aaaf52f6db2a72b49a39fcc0875;all_sr_blocks=202359001_110926404_2_1_0;checkin=2018-09-20;checkout=2018-09-24;dest_id=-578472;dest_type=city;dist=0;group_adults=2;hapos=20;highlighted_blocks=202359001_110926404_2_1_0;hpos=20;nflt=ht_id%3D204;room1=A%2CA;sb_price_type=total;srepoch=1536201776;srfid=e23272ea05361c214718e69e21075ccf8caf9ee7X20;srpvid=1d20131781220068;type=total;ucfs=1&#tab-main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Importaciones requeridas del programa\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizarFrase(frase):    \n",
    "    archivoTemporalConFrase = open('temporalFile.txt','w')    \n",
    "    archivoTemporalConFrase.write(frase)\n",
    "    archivoTemporalConFrase.close()\n",
    "\n",
    "    file = {'file': open('temporalFile.txt', 'r')}\n",
    "    params = {'outf': 'tagged', 'format': 'json'}\n",
    "\n",
    "    url = \"http://www.corpus.unam.mx/servicio-freeling/analyze.php\"\n",
    "    r = requests.post(url, files=file, params=params)\n",
    "    obj = r.json()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerDictionaryDeSenticol():\n",
    "    archivoDeBaseDeDatos = open('MLSenticon.txt','r',  encoding='cp1252')\n",
    "    palabras = archivoDeBaseDeDatos.read().split('\\n')\n",
    "    diccionarioDePalabrasConSentimientos = {}    \n",
    "    for palabra in palabras:\n",
    "        tmpPalabraConSentimiento = palabra.split('\\t')\n",
    "        diccionarioDePalabrasConSentimientos[tmpPalabraConSentimiento[0]] = tmpPalabraConSentimiento[1]\n",
    "    return diccionarioDePalabrasConSentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leerBaseDeDatosDeReviews():\n",
    "    archivoDeBaseDeDatos = open('database.txt','r')\n",
    "    reviewsData = archivoDeBaseDeDatos.read().split('\\n')\n",
    "    archivoDeBaseDeDatos.close()\n",
    "    reviews, tipoDeReview = [],[] \n",
    "    for reviewData in reviewsData:\n",
    "        temporalData = reviewData.split('\\t')\n",
    "        reviews.append(temporalData[0])\n",
    "        tipoDeReview.append(temporalData[1])\n",
    "    return reviews, tipoDeReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representacionVectorial(reviewTokenizado, diccionarioDeSentimientos):    \n",
    "    representacion = [0, 0]\n",
    "    palabrasDeNegacion = ['pero', 'no']\n",
    "    finalizacionDeFrase = ['.', ',']\n",
    "    signoParaMultiplicarLasPalabras = 1\n",
    "    representacionTemporal = [0, 0]\n",
    "    \n",
    "    \n",
    "    for sentence in reviewTokenizado: \n",
    "        for word in sentence:\n",
    "            lemma = word['lemma']\n",
    "            if (lemma in finalizacionDeFrase):\n",
    "                representacion[0] += representacionTemporal[0] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[1]\n",
    "                representacion[1] += representacionTemporal[1] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[0]\n",
    "                representacionTemporal = [0, 0]\n",
    "            elif (lemma in palabrasDeNegacion):\n",
    "                signoParaMultiplicarLasPalabras = signoParaMultiplicarLasPalabras * (- 1);\n",
    "            elif (word['tag'][0] == 'A' and lemma in diccionarioDeSentimientos.keys()):\n",
    "                representacionTemporal[0] = representacionTemporal[0] + (float(diccionarioDeSentimientos[lemma]) if (float(diccionarioDeSentimientos[lemma]) > 0) else 0)\n",
    "                representacionTemporal[1] = representacionTemporal[1] + (float(diccionarioDeSentimientos[lemma]) if (float(diccionarioDeSentimientos[lemma]) < 0) else 0)\n",
    "            representacion[0] += representacionTemporal[0] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[1]\n",
    "            representacion[1] += representacionTemporal[1] if (signoParaMultiplicarLasPalabras > 0) else representacionTemporal[0]\n",
    "            representacionTemporal = [0, 0]\n",
    "    representacion[1] *= -1 if (representacion[1] < 0) else 1\n",
    "    representacion[0] *= -1 if (representacion[0] < 0) else 1\n",
    "\n",
    "    return representacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_measures(Yestimado, Yteorico):\n",
    "    \n",
    "    CM = confusion_matrix(Yteorico, Yestimado)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    sens = TP/(TP+FN)\n",
    "    esp = TN/(TN+FP)\n",
    "    \n",
    "    return sens, esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepararDatosParaPintar(datoAPreparar):\n",
    "    return str(np.mean(datoAPreparar))[:5] + ' +/- '+ str(np.std(datoAPreparar))[:5]    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pintarDatos(Modelo, Eficiencia, especcificidad, sensibilidad, datoExtra):\n",
    "    print(\"Datos de\", Modelo)\n",
    "    datos = {'Eficiencia' : Eficiencia,\n",
    "                   'Espicificidad' : especcificidad,\n",
    "                    'Sensibilidad': sensibilidad}\n",
    "    if (datoExtra != 0):\n",
    "        datoExtra.update(datos)\n",
    "        datos = datoExtra\n",
    "    df = pd.DataFrame(datos)\n",
    "    print (tabulate(df, headers='keys', tablefmt='psql'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecinosMasCercanos(data, target, k_neighbors):\n",
    "    accAcum = []\n",
    "    sensAcum = []\n",
    "    espAcum = []\n",
    "\n",
    "    \n",
    "    for n_neighbor in k_neighbors:\n",
    "        model = KNN(n_neighbors = n_neighbor)\n",
    "        acc = []\n",
    "        sens = []\n",
    "        esp = []\n",
    "\n",
    "        for i in range(100):\n",
    "\n",
    "            Xtrain, Xtest, Ytrain, Ytest = train_test_split(data, target)\n",
    "            model.fit(Xtrain,Ytrain)\n",
    "\n",
    "            Yest = model.predict(Xtest)\n",
    "            s, e = error_measures(Yest,Ytest)\n",
    "            sens.append(s); esp.append(e)\n",
    "            acc.append(model.score(Xtest,Ytest))\n",
    "\n",
    "        accAcum.append(prepararDatosParaPintar(acc))\n",
    "        sensAcum.append(prepararDatosParaPintar(sens))\n",
    "        espAcum.append(prepararDatosParaPintar(esp))    \n",
    "        \n",
    "    pintarDatos('Vecinos Más Cercanos', accAcum, espAcum, sensAcum , {'k_neighbors' : k_neighbors})     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresionLogistica(data, target):\n",
    "    lr = LogisticRegression()\n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "    \n",
    "\n",
    "    for i in range(100):\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(data, target)\n",
    "        lr.fit(Xtrain,Ytrain)        \n",
    "        Yest = lr.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(lr.score(Xtest,Ytest))\n",
    "        \n",
    "    pintarDatos('Regresión Logística', [prepararDatosParaPintar(acc)], [prepararDatosParaPintar(esp)], [prepararDatosParaPintar(sens)] , 0)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificadorRandomForest(data, target, n_estimators):\n",
    "    \n",
    "    accAcum = []\n",
    "    sensAcum = []\n",
    "    espAcum = []\n",
    "\n",
    "    \n",
    "    for n_estimator in n_estimators:\n",
    "        model = RF(n_estimators = n_estimator)\n",
    "        acc = []\n",
    "        sens = []\n",
    "        esp = []\n",
    "\n",
    "        for i in range(100):\n",
    "\n",
    "            Xtrain, Xtest, Ytrain, Ytest = train_test_split(data, target)\n",
    "            model.fit(Xtrain,Ytrain)\n",
    "\n",
    "            Yest = model.predict(Xtest)\n",
    "            s, e = error_measures(Yest,Ytest)\n",
    "            sens.append(s); esp.append(e)\n",
    "            acc.append(model.score(Xtest,Ytest))\n",
    "\n",
    "        accAcum.append(prepararDatosParaPintar(acc))\n",
    "        sensAcum.append(prepararDatosParaPintar(sens))\n",
    "        espAcum.append(prepararDatosParaPintar(esp))    \n",
    "        \n",
    "    pintarDatos('Bosque Aleatorio', accAcum, espAcum, sensAcum , {'n_estimators' : n_estimators})     \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devolverDataEnVectores(data):\n",
    "    dataRepresentadaEnVectores = []\n",
    "    for review in data:\n",
    "        dataRepresentadaEnVectores.append(representacionVectorial(tokenizarFrase(review), diccionarioDeSentimientos))\n",
    "    return dataRepresentadaEnVectores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realizarModelos(datosAModelar, targetsParaModelar):\n",
    "    regresionLogistica(datosAModelar, targetsParaModelar)\n",
    "    vecinosMasCercanos(datosAModelar, targetsParaModelar, [1,3,5,7,9,15,25])\n",
    "    clasificadorRandomForest(datosAModelar, targetsParaModelar, [10,20,30,40,50])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtencion de datos\n",
    "data, target = leerBaseDeDatosDeReviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <----- Representacion de vectores con cargas --------->\n"
     ]
    }
   ],
   "source": [
    "# Representacion de vectores con cargas\n",
    "\n",
    "print(\" <----- Representacion de vectores con cargas --------->\")\n",
    "diccionarioDeSentimientos = obtenerDictionaryDeSenticol()\n",
    "dataRepresentadaEnVectores = devolverDataEnVectores(data)\n",
    "#print(dataRepresentadaEnVectores)\n",
    "realizarModelos(dataRepresentadaEnVectores, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con TfidVectorizer\n",
    "print(\" <----- Representacion TfidVectorizer --------->\")\n",
    "\n",
    "vector = TfidfVectorizer()\n",
    "vector.fit(data)\n",
    "bow = vector.transform(data)\n",
    "realizarModelos(bow,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con CountVectorizer\n",
    "\n",
    "print(\" <----- Representacion CountVectorizer --------->\")\n",
    "\n",
    "\n",
    "vector = CountVectorizer(ngram_range=(1,2))\n",
    "vector.fit(data)\n",
    "bow = vector.transform(data)\n",
    "realizarModelos(bow,target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
